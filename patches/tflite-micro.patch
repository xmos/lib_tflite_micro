diff --git tensorflow/lite/micro/memory_planner/greedy_memory_planner.h tensorflow/lite/micro/memory_planner/greedy_memory_planner.h
index 4c39e7c..b389476 100644
--- tensorflow/lite/micro/memory_planner/greedy_memory_planner.h
+++ tensorflow/lite/micro/memory_planner/greedy_memory_planner.h
@@ -108,6 +108,8 @@ class GreedyMemoryPlanner : public MicroMemoryPlanner {
         sizeof(int);                  // buffer_offsets_;
     return per_buffer_size;
   }
+  
+  TF_LITE_REMOVE_VIRTUAL_DELETE
 
  private:
   // Whether a buffer is active in a given time range.
@@ -158,8 +160,6 @@ class GreedyMemoryPlanner : public MicroMemoryPlanner {
 
   // Whether buffers have been added since the last plan was calculated.
   bool need_to_calculate_offsets_;
-
-  TF_LITE_REMOVE_VIRTUAL_DELETE
 };
 
 }  // namespace tflite
diff --git tensorflow/lite/micro/micro_allocator.cc tensorflow/lite/micro/micro_allocator.cc
index 51a1254..3cc3079 100644
--- tensorflow/lite/micro/micro_allocator.cc
+++ tensorflow/lite/micro/micro_allocator.cc
@@ -926,11 +926,26 @@ TfLiteStatus MicroAllocator::CommitStaticMemoryPlan(
   TF_LITE_ENSURE_STATUS(builder.AddScratchBuffers(scratch_buffer_requests,
                                                   scratch_buffer_handles));
 
+  // Find out size needed to allocate buffers
+  size_t buffer_size_needed = 0;
+  for (size_t i = 0; i < allocation_info_count; ++i) {
+    const AllocationInfo* current = &allocation_info[i];
+    if (current->needs_allocating) {
+      GreedyMemoryPlanner* memory_planner = (GreedyMemoryPlanner*)memory_planner_;
+      buffer_size_needed += memory_planner->per_buffer_size();
+    }
+  }
+  // We have to account for the memory needed for adding buffers which have to be allocated
+  // Note that this is only the memory needed for storing info about the buffers
+  memory_allocator_->CalculateMaxUsed(buffer_size_needed);
+
   // Remaining arena size that memory planner can use for calculating offsets.
   size_t remaining_arena_size =
       memory_allocator_->GetAvailableMemory(kBufferAlignment);
+  // All the remaining memory is being allocated as temp memory here.
+  // We don't want this to affect our calculation of max memory used
   uint8_t* planner_arena =
-      memory_allocator_->AllocateTemp(remaining_arena_size, kBufferAlignment);
+      memory_allocator_->AllocateTemp(remaining_arena_size, kBufferAlignment, /*affects_max=*/false);
   TF_LITE_ENSURE(error_reporter_, planner_arena != nullptr);
   memory_planner_->Init(planner_arena, remaining_arena_size);
   TF_LITE_ENSURE_STATUS(CreatePlan(error_reporter_, memory_planner_,
@@ -941,6 +956,8 @@ TfLiteStatus MicroAllocator::CommitStaticMemoryPlan(
 
   size_t actual_available_arena_size =
       memory_allocator_->GetAvailableMemory(kBufferAlignment);
+  // We have to account for the memory needed by the memory planner
+  memory_allocator_->CalculateMaxUsed(memory_planner_->GetMaximumMemorySize());
 
   // Make sure we have enough arena size.
   if (memory_planner_->GetMaximumMemorySize() > actual_available_arena_size) {
diff --git tensorflow/lite/micro/micro_error_reporter.h tensorflow/lite/micro/micro_error_reporter.h
index ac45224..d156b8a 100644
--- tensorflow/lite/micro/micro_error_reporter.h
+++ tensorflow/lite/micro/micro_error_reporter.h
@@ -40,7 +40,6 @@ class MicroErrorReporter : public ErrorReporter {
   ~MicroErrorReporter() override {}
   int Report(const char* format, va_list args) override;
 
- private:
   TF_LITE_REMOVE_VIRTUAL_DELETE
 };
 
diff --git tensorflow/lite/micro/micro_interpreter.h tensorflow/lite/micro/micro_interpreter.h
index 6650be8..8dfe808 100644
--- tensorflow/lite/micro/micro_interpreter.h
+++ tensorflow/lite/micro/micro_interpreter.h
@@ -127,6 +127,13 @@ class MicroInterpreter {
   // arena_used_bytes() + 16.
   size_t arena_used_bytes() const { return allocator_.used_bytes(); }
 
+  size_t operators_size() const { return model_->subgraphs()->Get(0)->operators()->size(); }
+
+  // For debugging only.
+  const NodeAndRegistration node_and_registration(int node_index)  {
+    return graph_.GetAllocations()[0].node_and_registrations[node_index];
+  }
+
  protected:
   const MicroAllocator& allocator() const { return allocator_; }
   const TfLiteContext& context() const { return context_; }
diff --git tensorflow/lite/micro/simple_memory_allocator.cc tensorflow/lite/micro/simple_memory_allocator.cc
index 08b6789..b9d8d00 100644
--- tensorflow/lite/micro/simple_memory_allocator.cc
+++ tensorflow/lite/micro/simple_memory_allocator.cc
@@ -34,7 +34,8 @@ SimpleMemoryAllocator::SimpleMemoryAllocator(ErrorReporter* error_reporter,
       buffer_tail_(buffer_tail),
       head_(buffer_head),
       tail_(buffer_tail),
-      temp_(buffer_head_) {}
+      temp_(buffer_head_),
+      max_used_(0) {}
 
 SimpleMemoryAllocator::SimpleMemoryAllocator(ErrorReporter* error_reporter,
                                              uint8_t* buffer,
@@ -82,6 +83,7 @@ TfLiteStatus SimpleMemoryAllocator::SetHeadBufferSize(size_t size,
   head_ = aligned_result + size;
   temp_ = head_;
 
+  CalculateMaxUsed();
   return kTfLiteOk;
 }
 
@@ -99,10 +101,11 @@ uint8_t* SimpleMemoryAllocator::AllocateFromTail(size_t size,
     return nullptr;
   }
   tail_ = aligned_result;
+  CalculateMaxUsed();
   return aligned_result;
 }
 
-uint8_t* SimpleMemoryAllocator::AllocateTemp(size_t size, size_t alignment) {
+uint8_t* SimpleMemoryAllocator::AllocateTemp(size_t size, size_t alignment, bool affects_max) {
   uint8_t* const aligned_result = AlignPointerUp(temp_, alignment);
   const size_t available_memory = tail_ - aligned_result;
   if (available_memory < size) {
@@ -112,7 +115,11 @@ uint8_t* SimpleMemoryAllocator::AllocateTemp(size_t size, size_t alignment) {
                          size, available_memory, size - available_memory);
     return nullptr;
   }
+
   temp_ = aligned_result + size;
+  if(affects_max) {
+    CalculateMaxUsed();
+  }
   return aligned_result;
 }
 
@@ -135,7 +142,7 @@ size_t SimpleMemoryAllocator::GetAvailableMemory(size_t alignment) const {
 }
 
 size_t SimpleMemoryAllocator::GetUsedBytes() const {
-  return GetBufferSize() - (tail_ - temp_);
+  return max_used_;
 }
 
 size_t SimpleMemoryAllocator::GetBufferSize() const {
@@ -146,4 +153,11 @@ uint8_t* SimpleMemoryAllocator::head() const { return head_; }
 
 uint8_t* SimpleMemoryAllocator::tail() const { return tail_; }
 
+void SimpleMemoryAllocator::CalculateMaxUsed(size_t extraToBeAdded) {
+  size_t tail_used = buffer_tail_ - tail_;
+  size_t head_used = std::max(head_ - buffer_head_, temp_ - buffer_head_);
+  size_t m = tail_used + head_used + extraToBeAdded;
+  max_used_ = std::max(max_used_, m);
+}
+
 }  // namespace tflite
diff --git tensorflow/lite/micro/simple_memory_allocator.h tensorflow/lite/micro/simple_memory_allocator.h
index 36ab80b..b34aa1f 100644
--- tensorflow/lite/micro/simple_memory_allocator.h
+++ tensorflow/lite/micro/simple_memory_allocator.h
@@ -63,7 +63,7 @@ class SimpleMemoryAllocator {
   // calls to AllocateTemp() must end with a call to ResetTempAllocations(). If
   // AllocateFromHead() is called before a call to ResetTempAllocations(), it
   // will fail with an error message.
-  virtual uint8_t* AllocateTemp(size_t size, size_t alignment);
+  virtual uint8_t* AllocateTemp(size_t size, size_t alignment, bool affects_max=true);
 
   // Resets a chain of temporary allocations back to the current head of the
   // arena (lowest address).
@@ -87,6 +87,10 @@ class SimpleMemoryAllocator {
   // account any temporary allocations.
   size_t GetUsedBytes() const;
 
+  // Calculates and sets the max used bytes in the allocator. This number takes in
+  // account any temporary allocations.
+  void CalculateMaxUsed(size_t extraToBeAdded = 0);
+
   TF_LITE_REMOVE_VIRTUAL_DELETE
 
  protected:
@@ -105,6 +109,7 @@ class SimpleMemoryAllocator {
   uint8_t* head_;
   uint8_t* tail_;
   uint8_t* temp_;
+  size_t max_used_;
 };
 
 }  // namespace tflite
